---
title: "ChatGPT系列：EP 01 - 第一印象"
date: 2023-09-09
permalink: /cn/chatgpt001/
tags: [chatgpt]
excerpt: "你会ChatGPT吗?"
mathjax: "true"
---

嗨哪！如果你亲自认识我，你就会知道我对ChatGPT简直着迷了。我不是特别喜欢它背后的所有技术细节，但我非常喜欢探索它可以做什么。
对我来说，大型语言模型（LLM）现阶段和任何由它驱动的成功产品（比如ChatGPT）简直是独一无二的，而不是一个昙花一现的趋势 - 尽管要看到它的辉煌意味着需要深入研究并给它时间。

几周前，发生了一件很酷的事情。那时我在办公室，和一个来自网络安全部门的同事聊天，不出所料，我们开始谈论ChatGPT。我们变得如此沉迷，以至于我们决定用一个真实的编码问题来测试GPT-4的解决问题的能力，这个问题是我同事之前与AWS支持团队讨论过的。

起初，我们不记得解决方案了，所以当GPT-4遇到一个“功能限制”的墙壁时，我们只是接受了它。但后来，我的同事突然灵光一闪，记起了AWS给出的解决方案。这让我们想知道：我们能指导GPT-4找到正确答案吗？

我花时间和我的同事澄清了编码问题并收集更多的上下文，然后我们将一个去敏感化的JSON文件喂给GPT-4（因为我相信这有助于提供上下文），最终我们得到了相同的解决方案。

我的同事对结果表示怀疑，认为知道事实真相让我能够返工指导GPT-4找到正确的答案，这是我所争议的，我强调虽然我引导GPT-4朝正确的方向，但我并没有直接给出答案。

<img src="{{ site.url }}{{ site.baseurl }}/assets/images/meme/notwrong_meme.jpg" alt="">

我也想强调，这里的要点真的不是谁对谁错，而是从这个简单的实验中得到的学习点是什么？
1. 我们是否在问正确的问题？ - 清晰表达我们的查询是至关重要的，这在当今受社交媒体驱动的世界中并不是一件容易的事情。
2. 确认偏误 - 这个实验显示了需要对AI（测试GPT-4）采取一种开放的、探索性的方法，避免简单地验证我们现有的信仰（ChatGPT 3.5很糟糕）。
3. 天真的现实主义 - 我们常常假设其他人，包括AI，都和我们一样看待事物，忽视了为不同受众适应我们的输入的必要性。

从本质上讲，我们的实验突显了我们所有人很久以前就认识到的人类特征，现在唯一的区别是AI加入了方程式，我们只是被分心了，忘记了我们作为人类的缺点。

那么，你对ChatGPT有什么看法？

<img src="{{ site.url }}{{ site.baseurl }}/assets/images/chatgpt/chatgpt_users.png" alt="">





