---
title: "More on Collaborative Filtering and Neural Network"
date: 2019-04-24
permalink: /collabnn/
tags: [fastai, deep learning, collaborative filtering, components of neural net]
excerpt: "Exploring components of neural net such as weights and biases, as well as the process of fine tuning"
mathjax: "true"
---

In the previous blogpost, we explored a little bit on **collaborative filtering and neural network**, we also talked about **embedding** and **bias**.

In this blogpost, we will review and further elaborate of what we have talked about in the past blogposts (e.g. transfer learning, discriminative learning rate, embedding, bias, etc.), we will also build a collab learner on MoviesLens 100k dataset to try to understand more about the concept of **weights** and **biases** in a neural network.

Let's review the very basic materials first...

# Typical components found in a deep neural network

This is a screenshot that is taken from [fast.ai](https://www.fast.ai/) course, which depicts what a typical deep neural net look like.

![nn_ss](https://forums.fast.ai/uploads/default/original/2X/7/770155ba66ee3b7f7a2b6effa6bf14ccc1e52bd1.jpeg)

**Type of Layers in a neural network:**

There are exactly two type of layers in a typical deep neural net.

  **1. Parameters**

  These are layers that contain parameters/weights, also called as linear layers which maintain state, For example, convolutions, linear.
Parameters are the things that your model learns, they are the nodes that are tweaked by the model when undergoing a gradient descent which minimizes the loss function

  > `parameter = parameter - learning_rate * parameter.grad`

  **2. Activations**

  We will understand this using the diagram above, if we look at the diagram above, we have got our *input activation* layer and we multiplied it by *parameters / weight tensors (highlighted in yellow)* to get an *activation layer (highlighted in cyan)*, so loosely speaking *activation* are numbers that are calculated, well, except *input activation (first layer)*.

 Another fact about activation is that it doesn't just come out from dot product in a matrix multiplication, it can also come out from an *activation function*, these *activations (highlighted in purple)* are activations that went through an *activation function*.

Some other important terminology you will often hear in neural net:

  **1. Activation Function**

  The most important thing to remember about an activation function is that it’s an element-wise function. It’s a function that is applied to each element of the input, activations in turn and creates one activation for each input element.

  There are a lot of activation functions out there, but using ReLu will get a decent result pretty much most of the time.

  It turns out that the combination of matrix multiplications followed by ReLu’s stacked together has this amazing mathematical property called the [Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem).
It says if you have big enough weight matrices and enough of them it can solve any arbitrarily complex mathematical function to any arbitrarily high level of accuracy assuming that you can train the parameters both in terms of time and data availability and so forth.

  **2. Backpropagation**

  [Backpropagation](https://en.wikipedia.org/wiki/Backpropagation) is shorthand for "the backward propagation of errors," since an error is computed at the output and distributed backwards throughout the network’s layers.

  I strongly recommend watching this [backpropagation video by 3Blue1Brown](https://www.youtube.com/watch?v=Ilg3gGewQ5U) to understand the concept.





# Fine Tuning

## Transfer Learning

Previously, we have built an image classifier using convolutional neural net with a resnet34 architecture, how does it actually work?

Remember that resnet34 is actually pre-trained weights, which was trained looking at about one and a half million pictures of thousands of different categories of things using an image data set called ImageNet. It turns out that the weight matrices on the last layer had a column of size 1000, it was trained to classify which of the 1000 different categories of item an image shows.

### Layer Deletion and Random Weights

Practically speaking, when we do the transfer learning, we probably do not want to classify a problem which has up to 1000 categories, for instance, the bear classifer that we built merely had 3 categories, even when we want to predict up to 1000 categories, we probably still aren't interested in this last layer of weight matrices, because the 1000 categories that we want to classify do not belong in the same categories as the ones from the ImageNet.

As a result, fastai library automatically delete the last layer of parameters, and create two new parameter layers with a ReLu in between. The size of the first parameter layer follows a default number set by fastai library, but the size of the second parameter layer depends on what we are trying to predict (Can be accessed with `data.c` assuming `data` is the variable name of our databunch object)


## Freezing Layers

Remember that when we call `fit_one_cycle`, the model freeze the early convolutional layers of the network and only train the last few layers which make a prediction. In another word, backpropagation will not go through the frozen layers.

### But why do we need to freeze?

Because we do not want to modify the parameters in the early convolutional layers of the network which is when the model learn about the basic components of an image, like diagonal edges in different directions, how the diagnonal edges can form a pattern, etc.

Intuitively speaking, we are only concern with the last few layers of the neural net because that's when the neural net truly learn about patterns that corresponds to our problem, that is why by default, fastai library doesn’t freeze the whole thing. It freezes everything except the randomly generated added layers that fastai puts on for us.

Another thing worthy of note would be that as we don't backpropagate as much, and so we store less gradients, which helps in terms of computational expense, which can be helpful in the beginning of the analysis, after everything is looking fine, we proceed to unfreezing the layers so that gradients are backpropagated to the very first parameter layer.

## Discriminative Learning Rate

When we pass in the argument for `max_lr` in `fit_one_cycle`, we are specifying the learning rate for our neural net, but we almost always set a discriminative learning rate, which means a higher learning rate in the end of the neural net and a lower learning rate in the early layers.

For instance, earlier layers of the model we might give a learning rate of 1e - 5 and newly added layers of the model we might give a learning rate of 1e - 3 because when the learning rate for the early layers is smaller it’s going to move them around less and that's what we want because we think they are already pretty good, and if we use a learning rate that is too high, it might diverge and make it worse.

### Options for specifying a learning rate

1. a single number like `max_lr = 1e-3`:
Just using a single number means every layer gets the same learning rate which means we are not using a discriminative learning rate.

2. you can write a slice, `max_lr = slice(1e-3):`
If we pass a single number to slice it means the final layers get a learning rate of (1e - 3) and then all the other layers get the same learning rate which is that divided by 3. All of the other layers will be (1e - 3) / 3 and the last layers will be 1e - 3.

3. You can write slice with two numbers, `max_lr = slice(1e-5, 1e-3)`
In this case, the final layers the these randomly hidden added layers will still be again 1e - 3.
The first layers will get 1e - 5. The other layers will get learning rates that are equally spread between those two numbers.

### Layer group

To further clarify the process, fastai library don’t actually give a different learning rate to every layer. It  gives a different learning rate to every **layer group** which is a bunch of layers grouped together.

By default, randomly added extra layers by fastai is grouped together as one layer group (can be modified), and the rest of the network is split in half into two layer groups.

With a CNN, we will get three layer groups, if we put `max_lr = slice(1e-5, 1e-3)`, we will get `1e-5` learning rate for the first layer group, `1e-4` learning rate for the second layer group and `1e-3` for the third layer group.

# Embedding

Lazy man explanation is that, there are two ways to do matrix multiplication between input activation and the weight matrices:

1. One hot encoded matrix input activation multiplied by the weight matrix
2. **Embedding** which is an array lookup which is a lot less memory intensive because its not creating one hot encoded version of input activation and therefore not doing matrix multiplication with all the zeros in the hot encoded matrix input activation.

So, whenever we hear people say embedding, we can always think of it as “an array lookup” which we know is mathematically identical to matrix multiply by a one hot encoded matrix.

# Bias

Let's look at this Excel spreadsheet which shows the user embedding, movie embedding which we also used in the previous blogpost.

![emb_wm](https://i.imgur.com/VYIsv3V.png)

## Without Bias

the output activation is derived from taking the dot product of user embedding matrix and movie embedding matrix. If we look at just one of the output activations, say `userid 293` and `movieid 72`, we see that it's derived from *user embedding vector (highlighted in red)* and *movie embedding vector (highlighted in purple)*

Intuitively speaking, *the user embedding vector might represent features of personal movie taste, and the movie embedding vector might represent the corresponding features of movies*. For example, if one of the value from the user embedding vector value is high (*this user likes Hugh Jackman*) and then one of the values from movie embedding vector is high (*this movie has Hugh Jackman*), the output activation will be high as well.

Now we are not saying that these embedding vector mean anything, because we do not know what they represent, but for gradient descent to perform well, it has to kind of figure out what the aspects of movie taste are and the corresponding features are, these features are called [latent features](https://en.wikipedia.org/wiki/Latent_variable).


**The Problem:**

Pan was a 2015 adventure, comedy, family film that stars Hugh Jackman, but it's probably Hugh Jackman worst movie, how do we account for this? How can we make sure that this movie is not on the recommendation? We introduce bias terms.






## With Bias

Here is the same thing again, the same construct, same shape of everything, but with an extra bias vector for user and movie respectively.

![bias](https://i.imgur.com/KRDDujB.png)


So now its not just the dot product between two embedding vectors, but also adding the bias terms.

## What is Bias in this context?

This means now each movie can have an overall “this is a great movie” versus “this isn’t a great movie” and every user can have an overall “this user rates movies highly” or “this user doesn’t rate movies highly” - that’s called the bias. This is the same usual linear model concept or linear layer concept from a neural net that we have a matrix product and a bias.

So really, by introducing bias terms, we can provide the model flexbility to account for other features that are not captured in the embedding vectors. we have also seen in previous blogpost how introducing bias term can provide more flexiblity to neural net mathematically.

Let's setup the environment and look at some dataset to understand more about these concepts.

# Colab Cloud Server VM setup & FastAI Configurations

First we need to use GPU for deep learning applications, so instead of buying, we can rent it from cloud servers. There are many other server options, but basically I chose Colab because issa FREE.

To learn how to set up a Colab Server which supports fastai library and its applications, click [here](https://course.fast.ai/start_colab.html).

NB: This is a free service that may not always be available, and requires extra steps to ensure your work is saved. Be sure to read the docs on the Colab web-site to ensure you understand the limitations of the system.


```python
# Permit collaboratory instance to read/write to Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
base_dir = root_dir + 'fastai-v3/'
```

    Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code

    Enter your authorization code:
    ··········
    Mounted at /content/gdrive



```python
  !curl -s https://course.fast.ai/setup/colab | bash
```

    Updating fastai...
    Done.



```python
%reload_ext autoreload
%autoreload 2
%matplotlib inline
```


```python
from fastai.collab import *
from fastai.tabular import *
```

# Movielens 100k

## Getting the data

Let's try with the full Movielens 100k data dataset,

1. Download from http://files.grouplens.org/datasets/movielens/ml-100k.zip
2. Create a subdirectory under 'data' and name it 'ml-100k'
3. Unzip the zip file and upload to 'data/ml-100k'


```python
# define path
path = Path('/content/data/ml-100k')
```


```python
# create 'fastai-v3/data/ml-100k' folder
path.mkdir(parents=True, exist_ok=True)

# drag and drop 'ml-100k' folder to path
```


```python
user,item,title = 'userId','movieId','title'
```


```python
ratings = pd.read_csv(path/'u.data', delimiter='\t', header=None,
                      names=[user,item,'rating','timestamp'])
ratings.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
      <td>881250949</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186</td>
      <td>302</td>
      <td>3</td>
      <td>891717742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>377</td>
      <td>1</td>
      <td>878887116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>244</td>
      <td>51</td>
      <td>2</td>
      <td>880606923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166</td>
      <td>346</td>
      <td>1</td>
      <td>886397596</td>
    </tr>
  </tbody>
</table>
</div>




```python
movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1', header=None,
                    names=[item, 'title', 'date', 'N', 'url', *[f'g{i}' for i in range(19)]])
movies.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
      <th>title</th>
      <th>date</th>
      <th>N</th>
      <th>url</th>
      <th>g0</th>
      <th>g1</th>
      <th>g2</th>
      <th>g3</th>
      <th>g4</th>
      <th>...</th>
      <th>g9</th>
      <th>g10</th>
      <th>g11</th>
      <th>g12</th>
      <th>g13</th>
      <th>g14</th>
      <th>g15</th>
      <th>g16</th>
      <th>g17</th>
      <th>g18</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>01-Jan-1995</td>
      <td>NaN</td>
      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>GoldenEye (1995)</td>
      <td>01-Jan-1995</td>
      <td>NaN</td>
      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Four Rooms (1995)</td>
      <td>01-Jan-1995</td>
      <td>NaN</td>
      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Get Shorty (1995)</td>
      <td>01-Jan-1995</td>
      <td>NaN</td>
      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Copycat (1995)</td>
      <td>01-Jan-1995</td>
      <td>NaN</td>
      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




```python
len(ratings)
```




    100000




```python
rating_movie = ratings.merge(movies[[item, title]])
rating_movie.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>timestamp</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
      <td>881250949</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>242</td>
      <td>3</td>
      <td>875747190</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>226</td>
      <td>242</td>
      <td>5</td>
      <td>883888671</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>154</td>
      <td>242</td>
      <td>3</td>
      <td>879138235</td>
      <td>Kolya (1996)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>306</td>
      <td>242</td>
      <td>5</td>
      <td>876503793</td>
      <td>Kolya (1996)</td>
    </tr>
  </tbody>
</table>
</div>




```python
data = CollabDataBunch.from_df(rating_movie, seed=42, valid_pct=0.1, item_name=title)
```

By default, a `CollabDataBunch` object will assume the first column to be the `users`, the second column to be the `items` and the third column to be `ratings`, and since we are using `title` as our `item`, we have to explicitly put it in the argument `item_name=title`.


```python
data.show_batch()
```


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>userId</th>
      <th>title</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>379</td>
      <td>Liar Liar (1997)</td>
      <td>3.0</td>
    </tr>
    <tr>
      <td>710</td>
      <td>GoodFellas (1990)</td>
      <td>4.0</td>
    </tr>
    <tr>
      <td>389</td>
      <td>Sleepless in Seattle (1993)</td>
      <td>3.0</td>
    </tr>
    <tr>
      <td>402</td>
      <td>Men in Black (1997)</td>
      <td>4.0</td>
    </tr>
    <tr>
      <td>719</td>
      <td>Twister (1996)</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>



```python
y_range = [0,5.5]
```

The reason why the `y_range` is set to between 0 to 5.5 is because if we set it between 0 to 5, it would mean that the sigmoid function asymptote to 5, but will never get to 5, which is not true since its possible for movies to get a perfect 5 rating.

As a result, `y_range` is then set to be 0 to 5.5.


```python
learn = collab_learner(data, n_factors=40, y_range=y_range, wd=1e-1)
```

Loosely speaking, `n_factors` stands for number of factors and is the width of the embedding matrix, feel free to try different amount of factors to get the best results.


```python
learn.lr_find()
learn.recorder.plot(skip_end=15, suggestion = True)
```





    LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
    Min numerical gradient: 6.31E-07



<img src="{{ site.url }}{{ site.baseurl }}/assets/images/collabnn/output_39_2.png" alt="">



```python
learn.fit_one_cycle(5, 6e-3)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/collabnn/output_01_0.png" alt="">



```python
learn.save('dotprod')
```

Here's [some benchmarks](https://www.librec.net/release/v1.3/example.html) on the same dataset for the popular Librec system for collaborative filtering. They show best results based on RMSE of 0.91, which corresponds to an MSE of `0.91**2 = 0.83`, and we are getting `0.817`, take this with a grain of salt because we are using different train and validation sets, but still, its pretty decent!

## Interpretation

### Setup


```python
learn.load('dotprod');
```


```python
learn.model
```




    EmbeddingDotBias(
      (u_weight): Embedding(944, 40)
      (i_weight): Embedding(1654, 40)
      (u_bias): Embedding(944, 1)
      (i_bias): Embedding(1654, 1)
    )




```python
g = rating_movie.groupby(title)['rating'].count()
top_movies = g.sort_values(ascending=False).index.values[:1000]
top_movies[:10]
```




    array(['Star Wars (1977)', 'Contact (1997)', 'Fargo (1996)', 'Return of the Jedi (1983)', 'Liar Liar (1997)',
           'English Patient, The (1996)', 'Scream (1996)', 'Toy Story (1995)', 'Air Force One (1997)',
           'Independence Day (ID4) (1996)'], dtype=object)



### Movie bias


```python
movie_bias = learn.bias(top_movies, is_item=True)
movie_bias.shape
```




    torch.Size([1000])




```python
mean_ratings = rating_movie.groupby(title)['rating'].mean()
movie_ratings = [(b, i, mean_ratings.loc[i]) for i,b in zip(top_movies,movie_bias)]
```


```python
item0 = lambda o:o[0]
```


```python
sorted(movie_ratings, key=item0)[:15]
```




    [(tensor(-0.3661),
      'Children of the Corn: The Gathering (1996)',
      1.3157894736842106),
     (tensor(-0.3311),
      'Lawnmower Man 2: Beyond Cyberspace (1996)',
      1.7142857142857142),
     (tensor(-0.3054), 'Mortal Kombat: Annihilation (1997)', 1.9534883720930232),
     (tensor(-0.2895), 'Striptease (1996)', 2.2388059701492535),
     (tensor(-0.2884), 'Cable Guy, The (1996)', 2.339622641509434),
     (tensor(-0.2642), 'Bio-Dome (1996)', 1.903225806451613),
     (tensor(-0.2630), 'Island of Dr. Moreau, The (1996)', 2.1578947368421053),
     (tensor(-0.2521), 'Barb Wire (1996)', 1.9333333333333333),
     (tensor(-0.2518), 'Leave It to Beaver (1997)', 1.8409090909090908),
     (tensor(-0.2483), 'Free Willy 3: The Rescue (1997)', 1.7407407407407407),
     (tensor(-0.2477), 'Grease 2 (1982)', 2.0),
     (tensor(-0.2458), "McHale's Navy (1997)", 2.1884057971014492),
     (tensor(-0.2442), 'Thinner (1996)', 2.4489795918367347),
     (tensor(-0.2352), "Joe's Apartment (1996)", 2.2444444444444445),
     (tensor(-0.2330), 'Beautician and the Beast, The (1997)', 2.313953488372093)]



Above shows top 15 movies with the lowest movie bias, which corresponds to low mean rating.


```python
sorted(movie_ratings, key=lambda o: o[0], reverse=True)[:15]
```




    [(tensor(0.6489), "Schindler's List (1993)", 4.466442953020135),
     (tensor(0.6265), 'Shawshank Redemption, The (1994)', 4.445229681978798),
     (tensor(0.6068), 'Titanic (1997)', 4.2457142857142856),
     (tensor(0.5830), 'Good Will Hunting (1997)', 4.262626262626263),
     (tensor(0.5619), 'Star Wars (1977)', 4.3584905660377355),
     (tensor(0.5541), 'Rear Window (1954)', 4.3875598086124405),
     (tensor(0.5501), 'As Good As It Gets (1997)', 4.196428571428571),
     (tensor(0.5501), 'Silence of the Lambs, The (1991)', 4.28974358974359),
     (tensor(0.5416), 'Usual Suspects, The (1995)', 4.385767790262173),
     (tensor(0.5402), 'Casablanca (1942)', 4.45679012345679),
     (tensor(0.5362), 'Apt Pupil (1998)', 4.1),
     (tensor(0.5351), 'L.A. Confidential (1997)', 4.161616161616162),
     (tensor(0.5027), "One Flew Over the Cuckoo's Nest (1975)", 4.291666666666667),
     (tensor(0.4973), 'Close Shave, A (1995)', 4.491071428571429),
     (tensor(0.4919), 'Godfather, The (1972)', 4.283292978208232)]



These shows top 15 movies with the highest movie bias, which corresponds to high mean rating.

### Movie weights


```python
movie_w = learn.weight(top_movies, is_item=True)
movie_w.shape
```




    torch.Size([1000, 40])



it's quite daunting to look at 40 weights at once, and so we use PCA which does a simple linear transformation that takes its input values and find a smaller number of columns that cover a lot of space of the original matrix.


```python
movie_pca = movie_w.pca(3)
movie_pca.shape
```




    torch.Size([1000, 3])




```python
# Look at first principal component
fac0,fac1,fac2 = movie_pca.t()
movie_comp = [(f, i) for f,i in zip(fac0, top_movies)]
```


```python
sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]
```




    [(tensor(1.0896), 'Close Shave, A (1995)'),
     (tensor(1.0508), 'Casablanca (1942)'),
     (tensor(1.0244), 'Lawrence of Arabia (1962)'),
     (tensor(1.0065), 'Chinatown (1974)'),
     (tensor(0.9995), 'Ran (1985)'),
     (tensor(0.9930), 'Secrets & Lies (1996)'),
     (tensor(0.9846), 'Wrong Trousers, The (1993)'),
     (tensor(0.9571),
      'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)'),
     (tensor(0.9367), 'Apocalypse Now (1979)'),
     (tensor(0.9363), 'When We Were Kings (1996)')]




```python
sorted(movie_comp, key=itemgetter(0))[:10]
```




    [(tensor(-1.2418), 'Home Alone 3 (1997)'),
     (tensor(-1.2222), 'Jungle2Jungle (1997)'),
     (tensor(-1.1569), "McHale's Navy (1997)"),
     (tensor(-1.0882), 'Flipper (1996)'),
     (tensor(-1.0797), 'Children of the Corn: The Gathering (1996)'),
     (tensor(-1.0768), 'Congo (1995)'),
     (tensor(-1.0598), 'D3: The Mighty Ducks (1996)'),
     (tensor(-1.0486), 'Bio-Dome (1996)'),
     (tensor(-1.0095), 'Batman & Robin (1997)'),
     (tensor(-1.0093), 'Mortal Kombat: Annihilation (1997)')]



When we look at the first principal component, we are trying to understand what these factors represent, although we won't know exactly but it represent, we are sure that it has something to do with aspect of movie taste and movie feature.

It seems to me that when the movie weight is about 1, the movies seem to be in the drama/mystery genre, and when the movie weight is about -1, the movies are in the family/adventure genre, but hey I could be wrong.


```python
# Let's checkout 2nd Principal Component
movie_comp = [(f, i) for f,i in zip(fac1, top_movies)]
```


```python
sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]
```




    [(tensor(1.1798), 'Braveheart (1995)'),
     (tensor(1.0492), 'Titanic (1997)'),
     (tensor(1.0087), 'Raiders of the Lost Ark (1981)'),
     (tensor(0.8912), 'Pretty Woman (1990)'),
     (tensor(0.8776), 'American President, The (1995)'),
     (tensor(0.8766), "It's a Wonderful Life (1946)"),
     (tensor(0.8468), 'Independence Day (ID4) (1996)'),
     (tensor(0.8362), 'Affair to Remember, An (1957)'),
     (tensor(0.8056), 'Forrest Gump (1994)'),
     (tensor(0.8052), 'True Lies (1994)')]




```python
sorted(movie_comp, key=itemgetter(0))[:10]
```




    [(tensor(-0.8331), 'Ready to Wear (Pret-A-Porter) (1994)'),
     (tensor(-0.8233), 'Keys to Tulsa (1997)'),
     (tensor(-0.7924), 'Very Brady Sequel, A (1996)'),
     (tensor(-0.7845), 'Brazil (1985)'),
     (tensor(-0.7831), 'Stupids, The (1996)'),
     (tensor(-0.7675), 'Beavis and Butt-head Do America (1996)'),
     (tensor(-0.7635), 'Trainspotting (1996)'),
     (tensor(-0.7619), 'Crumb (1994)'),
     (tensor(-0.7403), 'Cable Guy, The (1996)'),
     (tensor(-0.7384), 'Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)')]



It seems like 2nd principal component picked up another interesting feature of taste, which seemingly separates positive and inspirational type of movies versus the negative and dystopian type of movies, I could be wrong though, I never watched most of these movies.

If you are into visualization, here's a visualization of the first principal component and the 2nd principal component, we could look at the third principal component also, but I am lazy.


```python
idxs = np.random.choice(len(top_movies), 40, replace=False)
idxs = list(range(30))
X = fac0[idxs]
Y = fac1[idxs]
plt.figure(figsize=(15,15))
plt.scatter(X, Y)
for i, x, y in zip(top_movies[idxs], X, Y):
    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)
    plt.xlabel('Fac0')
    plt.ylabel('Fac1')
plt.show()
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/collabnn/output_68_0.png" alt="">


If we want our recommender system to be based on the visualization above, we would probably want to recommend movies that are close to what a user like, so if a user like Willy Wonka and the Chocolate Factory, we would be recommending English Patient, as well as Monthy Python and the Holy Grail to the user.

Alternatively, we could look at the movie weights and recommend movies with weights that are close to the movie weights of movies that a user like.

Let's review the source code of the underlying model.

# Understanding the Source Code of `collab_leaner`

Let's have a look at the source code of  `collab_learner`.

![collab_learner](https://i.imgur.com/Wo43a43.png)

`collab_learner` takes a databunch `data`

`use_nn`: The architecture option for this case is whether we want multi-layer neural net or a classic collaborative filtering, since we will only be using the classic collaborative filtering for now, we set `use_nn = False`

`wd` (***learn_kwargs*): This is the weight decay, which is the parameter for regularization, when its = 0, it means no regularization. If you know about ridge regression, its basically the lambda parameter in the ridge regression penalty (note: it does not show in the source code because this is a kwargs and is a parameter that will be passed up the chain to the *Learner* constructor)

`EmbeddingDotBias`: We create an `EmbeddingDotBias` model and then we pass back a `CollabLearner` which has our data and that model


```python
# Learner constructor has `wd`
Learner.__annotations__
```




    {'add_time': bool,
     'bn_wd': bool,
     'callback_fns': typing.Collection[typing.Callable],
     'callbacks': typing.Collection[fastai.callback.Callback],
     'data': fastai.basic_data.DataBunch,
     'layer_groups': typing.Collection[torch.nn.modules.module.Module],
     'loss_func': typing.Callable,
     'metrics': typing.Collection[typing.Callable],
     'model': torch.nn.modules.module.Module,
     'model_dir': typing.Union[pathlib.Path, str],
     'opt_func': typing.Callable,
     'path': str,
     'train_bn': bool,
     'true_wd': bool,
     'wd': typing.Union[float, typing.Collection[float]]}



![edb](https://i.imgur.com/lpYbGPa.png)

This particular line of code creates a PyTorch nn.Module embedding matrix for us.

```
(self.u_weight, self.i_weight, self.u_bias, self.i_bias) = [embedding(*o) for o in [
            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)
        ]]
```

`forward` has been explained in the previous blogpost, basically involve all the calculations to get our predictions.

`torch.sigmoid`: we then wrap a sigmoid function to make sure the activation is between `y_range[0]` and `y_range[1]`


The whole of this section is to understand what is really going on when we call `collab_learner`, expectedly, its just:
  - dot product of users weight and items weight
  - sum of the dot product + users bias + items bias
  - go through sigmoid activation function (if `y_range` is specified)


# Important Terminology


In the previous blogpost, we have mentioned some important terminology used in the neural net, the bolded terminlogy below should not be unfarmiliar to us at this point:

- **Inputs**

- **Weights/parameters**
  - **Random**

- **Activations**
- **Activation functions / nonlinearities (e.g. ReLU / sigmoid)**
- **Outputs**
- **Loss**
- Metric
- Cross-entropy
- Softmax
- **Fine tuning**
- **Layer deletion and random weights**
- **Freezing & unfreezing**

Now would be a good checkpoint to stop, in the next blogpost, we will extensively talk about weight decay, which is a regularization parameter, which we have used as one of the arguments in `collab_learner`, and doing gradient descent in Excel to understand more about the subject, see you!
