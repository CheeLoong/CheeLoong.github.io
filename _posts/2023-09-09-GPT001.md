---
title: "ChatGPT Series: EP 01 - First Impressions"
date: 2023-09-09
permalink: /chatgpt001/
tags: [chatgpt]
excerpt: "Do you even ChatGPT bro?"
mathjax: "true"
---

Hey there! If you know me personally, you know I'm pretty much hooked on ChatGPT. I'm not exactly a fan of all the technical stuff behind it, but I just love exploring what it can do.
To me, the current stage of Large Language Models (LLMs) along with any successful products (such as ChatGPT) powered by it is in a league of its own rather than a passing trend - although getting to see its brilliance does mean being willing to dive in and give it time. 

A few weeks ago, something cool happened. So, I was at the office, ended up chatting with a colleague from cybersecurity, and, no surprise here, we got talking about ChatGPT. We got so engrossed that we decided to test GPT-4's problem-solving skills using a real-world coding issue that my colleague had discussed with AWS support.

At first, we didn’t remember the solution, so when GPT-4 hit a wall and cited a "feature limitation", we just accepted it. But then, my colleague had a lightbulb moment and remembered the solution AWS had given. That got us wondering: could we guide GPT-4 to the correct answer?

I took the time to clarify with my colleague on the coding issue and gather more context, we then fed a de-sensitized JSON file to GPT-4 (as I believe this helps provide context), and we eventually got the same solution. 

My colleague expressed skepticism about the results, arguing that knowing the ground truth allowed me to retroactively guide GPT-4 to the correct answer, a claim which I disputed, emphasizing that while I nudged GPT-4 in the right direction, I did not provide it with the answer outright.

<img src="{{ site.url }}{{ site.baseurl }}/assets/images/meme/notwron_meme.jpg" alt="">

I'd like to also emphasize that the takeaway here really isn't about who's right or who's wrong but rather the learning points from this simple experiment? 
1. Are we even asking the right questions? - It’s critical to articulate our queries well, something that isn't a given in today's social media-driven world.
2. Confirmation Bias - This experiment showed the need for an open, exploratory approach to AI (testing GPT-4), steering clear of simply validating our existing beliefs (ChatGPT 3.5 sucks).
3. Naïve Realism - We often assume that others, including AI, perceive things just as we do, overlooking the necessity to adapt our inputs for different audiences.

At its core, our experiment highlighted human traits that we all recognise since long time ago, the only difference now is that AI is in the equation, and we are simply distracted and forget the flaws we have as humans.

So, what do you think about ChatGPT? 

<img src="{{ site.url }}{{ site.baseurl }}/assets/images/chatgpt/chatgpt_users.png" alt="">





