---
title: "Data Augmentation, Convolutions & CNN from scratch"
date: 2019-05-18
permalink: /pets-cnn/
tags: [fastai, data augmentation, cnn, pets, stride2conv, heatmap]
excerpt: "We will further explore CNN on pets dataset"
mathjax: "true"
published: false
---

We are revisiting one of our favourite datasets, the pet dataset, it's one of the very first dataset we played with on this blog, we created an image classifier on this dataset to predict the breeds of cats and dogs.

This time, we will discuss the concept of data augmentation, the idea of convolutions and also builing a CNN using this dataset. Let's first set up the cloud and importing the data.

# Colab Cloud Server VM setup & FastAI Configurations

To learn how to set up a Colab Server which supports fastai library and its applications, [click here](https://course.fast.ai/start_colab.html).  There are many other server options, but basically I chose Colab because issa **FREE**.

NB: This is a free service that may not always be available, and requires extra steps to ensure your work is saved. Be sure to read the docs on the Colab web-site to ensure you understand the limitations of the system.


```python
# Permit collaboratory instance to read/write to Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
base_dir = root_dir + 'fastai-v3/'
```

    Mounted at /content/gdrive


We import all the necessary packages. We are going to work with the [fastai V1 library](http://www.fast.ai/2018/10/02/fastai-ai/) which sits on top of [Pytorch 1.0](https://hackernoon.com/pytorch-1-0-468332ba5163). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.


```python
from fastai.vision import *
```


```python
# this line creates data & models folder and functionalities integration (e.g. untar_data, model.save)  
  !curl -s https://course.fast.ai/setup/colab | bash
```

    Updating fastai...
    Done.


Every notebook starts with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook.


```python
%reload_ext autoreload
%autoreload 2
%matplotlib inline
```

## Import data


```python
bs = 64
```


```python
# the source for this dataset is from fast.ai
path = untar_data(URLs.PETS)/'images'
```

## Data Augmentation


```python
tfms = get_transforms(max_rotate=20, max_zoom=1.3, max_lighting=0.4, max_warp=0.4,
                      p_affine=1., p_lighting=1.)
```

Part of data augmentation is to call `get_transforms` but when we call that function, we can pass in a bunch of parameters, information can be found form this [doc link](https://docs.fast.ai/vision.transform.html#get_transforms), but we will talk about the interesting ones here.

Previously, we have used `get_transforms`, but we were using the defaults and at that time, all we had to know is that it does centre cropping and resizing the image to 224 x 224.


```python
# create an Image Item list, then split 20% of the data as validation set
src = ImageList.from_folder(path).split_by_rand_pct(0.2, seed=2)
```

We are defining a function to manually create `.databunch` because we want to specify `padding_mode`, that is why we aren't using `ImageDataBunch` this time.


```python
def get_data(size, bs, padding_mode='reflection'):
    return (src.label_from_re(r'([^/]+)_\d+.jpg$')
           .transform(tfms, size=size, padding_mode=padding_mode)
           .databunch(bs=bs).normalize(imagenet_stats))
```


```python
# Turning padding_mode to 'zeros'
data = get_data(224, bs, 'zeros')
```

We are going to create a 3x3 grids showing an image from a training set, we will define a function `_plot` to extract the image data from our training set and use `plot_multi`to plot it on multiple grids.


```python
def _plot(i,j,ax):
    x,y = data.train_ds[9]
    x.show(ax, y=y)

# plot_multi creates grid plot which calls the function from the first argument
plot_multi(_plot, 3, 3, figsize=(8,8))
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_21_0.png" alt="">


We see the same photo using different kind of data augmentation because this is from the training set, and we have applied data augmentation on the training set.

**Why is this useful?**

Think about it, if we were to build an image classifier of a particular object, to get a better predicition power, we would want our model to learn the photo not just from a professional camera shoot, but also from a variety of other angles, by doing data augmentation, we are essentially getting all these without manually taking photos of the same object 3000 times, this is all free extra data!


```python
# Let's try `padding_mode = reflection` (default)
data = get_data(224,bs)
```


```python
plot_multi(_plot, 3, 3, figsize=(8,8))
```


![png](output_24_0.png)


In practice, `padding_mode = reflection` is better because a real photo most likely would not have the dark borders like the ones we see in `padding_mode = zeros`.

## Train a model


```python
gc.collect()
learn = cnn_learner(data, models.resnet34, metrics=error_rate, bn_final=True)
```

    Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth
    100%|██████████| 87306240/87306240 [00:01<00:00, 83958165.39it/s]



```python
learn.fit_one_cycle(3, slice(1e-2), pct_start=0.8)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_01_0.png" alt="">



```python
learn.unfreeze()
learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-3), pct_start=0.8)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_01_1.png" alt="">




```python
data = get_data(352,bs)
learn.data = data
```


```python
learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_01_2.png" alt="">




```python
learn.save('352')
```

## Convolutions

It's time to learn what does it mean to be a convolution neural network, first we look at the standard fully connected neural net which looks something like what we have seen before in the [previous blogpost](https://cheeloong.github.io/collabnn/#) which looks like this:

<img src="https://forums.fast.ai/uploads/default/original/2X/7/770155ba66ee3b7f7a2b6effa6bf14ccc1e52bd1.jpeg" width="800">


Instead of doing the matrix multiplications between activation and parameter layers, we instead do a *convolution*.

<br>

**What is a convolution?**

A convolution takes in activation, and do an *element-wise matrix multiplication (herein refer as EWMM)* with a convolution kernel, here's how a *convolution kernel* looks like:

<img src="https://i.imgur.com/zJWSof6.png" width="800">

<img src="https://cdn-images-1.medium.com/max/2600/1*B0oEfpGMcXncp2ePKcyH6Q.gif" width="800"  align="middle">

<div align="center">
<a href="http://setosa.io/ev/image-kernels/">http://setosa.io/ev/image-kernels/</a>
</div>

Notice that there is a dark border around the output image, that is because we can't take 3x3 grid of the edges, top corner edge for instance only has 3 neighbours, this is where reflection padding or zero padding comes into play, for this particular visualization, the author has decided to ignore these values and make them black instead.

<br>

**So what actually happened?**

By doing element-wise multiplication between all the possible combination of 3x3 input activations and the 3x3 kernel, we have turned the inputs to an output which has white parts that outline horizontal edges, and this process is called a convolution, and the output of a convolution is called a **channel**.

<br>

**Visualizing zero padding by pixels**

Imagine we have a kernel of 3x3, and our image is also 3x3, in that case, we would only have 1 pixel output, because there is only 1 possible element-wise matrix multiplication, so what zeros padding does, is adding bunch of zero activations around the original input as shown below:

<img src="https://cdn-images-1.medium.com/max/1600/1*m8oHuCZMBK6gghLXr1bY8Q.png" width="500">

in fast.ai, reflection padding is more common that zero padding as explained previously, but the underlying objective is the same; which is to preserve the image size, feel free to read more from [this medium article](https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c) to learn more about it.

<br>

**What if we have a 3-Dimensional input activations?**

So if we have a standard RGB picture, we would have 3D input activations, do we still do the same with the original 3x3 convolution kernel?

*Short answer, no, Long answer? noooooooo. Just kidding..*

Supposed we want to build a classifier for an apple, we probably want a higher activations for red and maybe green than say blue, with that logic in mind, we would want different kernel values for each of the red, green, blue channel, that means we would create a 3 x 3 x 3 convolution kernel, instead of EWMM of 3 x 3 = 9, we are doing EWMM of 3 x 3 x 3 = 27.

Ok, we have created an output outlining the horizontal edges, what now? We are not done yet, we need more outputs, outlining other different edges, gradient, or whatever is inside an image, so we create another 3 x 3 x 3 convolution kernel with different values which will give us an output outlining different thing.

Say we have 16 different convolution kernels, our convolution would look something like this:

<img src="https://i.imgur.com/K8K4qgn.png" width="600">

We started with rank 3 input tensor with some height * width * depth (=3), and we end up with a rank 3 output tensor with height * width * depth (=16) because we have 16 different convolution kernels.

Now we have 16 different channels represening how much top edge, how much left edge, how much blue to green gradient of a particular image, etc.

We take this 16 channels, and do EWMM again with 16 different convolution kernels, and so we get another rank 3 tensor with height * width * depth (=16), and then we repeat for..however large we want our network to be.

<br>

**Memory problem & Stride 2 Convolution**

As we get deeper and deeper into our network, we want to have more channels, because we want to find richer feature as we dig deeper in the network, and in order to avoid memory from going overboard, from time to time, we create convolution where we don't step over every single possible combinations in the element-wise multiplication, instead we skip over 2 at a time. so say we do a 3x3 EWMM on a pixel centered at pixel (2, 2), we would skip pixel (2, 3) and do it on pixel (2, 4), then skip pixel (2, 5) and do pixel (2, 6) and so forth, and that is known as **stride 2 convolution**.

and generally when we do this, we will use twice as much convolution kernel, so our output tensor ends up with *height/2 * width/2 * (2 * depth)* which looks something like...

<img src="https://i.imgur.com/XAELzEu.png" width="600">










## Convolution net from scratch


```python
data = get_data(size = 352, bs = 16)
```


```python
data
```




    ImageDataBunch;

    Train: LabelList (5912 items)
    x: ImageList
    Image (3, 352, 352),Image (3, 352, 352),Image (3, 352, 352),Image (3, 352, 352),Image (3, 352, 352)
    y: CategoryList
    german_shorthaired,yorkshire_terrier,Bombay,leonberger,staffordshire_bull_terrier
    Path: /root/.fastai/data/oxford-iiit-pet/images;

    Valid: LabelList (1478 items)
    x: ImageList
    Image (3, 352, 352),Image (3, 352, 352),Image (3, 352, 352),Image (3, 352, 352),Image (3, 352, 352)
    y: CategoryList
    saint_bernard,leonberger,keeshond,japanese_chin,english_cocker_spaniel
    Path: /root/.fastai/data/oxford-iiit-pet/images;

    Test: None




```python
learn = cnn_learner(data, models.resnet34, metrics=error_rate, bn_final=True).load('352')
```


```python
# 420th photo in our valid set is a pug
idx= 420
x,y = data.valid_ds[idx]
x.show()
data.valid_ds.y[idx]
```




    Category pug




<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_39_1.png" alt="">


So here we are manually building a 3 x 3 convolution kernel, and because our image has 3 channels (RGB), we then expand it by making 3 copies (technically not copies but refer to the kernel we have created) which makes it 3 x 3 x 3.

In practice for our convolution kernel, we usually use a rank 4 tensor, because the first number represents the number of different convolution kernels we have, in this case, we are just trying to capture bottom right edge, so its just going to be 1.



```python
k = tensor([
    [0.  ,-5/3,1],
    [-5/3,-5/3,1],
    [1.  ,1   ,1],
]).expand(1,3,3,3)/6
```


```python
k
```




    tensor([[[[ 0.0000, -0.2778,  0.1667],
              [-0.2778, -0.2778,  0.1667],
              [ 0.1667,  0.1667,  0.1667]],

             [[ 0.0000, -0.2778,  0.1667],
              [-0.2778, -0.2778,  0.1667],
              [ 0.1667,  0.1667,  0.1667]],

             [[ 0.0000, -0.2778,  0.1667],
              [-0.2778, -0.2778,  0.1667],
              [ 0.1667,  0.1667,  0.1667]]]])




```python
k.shape
```




    torch.Size([1, 3, 3, 3])




```python
# the photo in the test set we have selected earlier
data.valid_ds[420]
```




    (Image (3, 352, 352), Category pug)




```python
# grab the shape of that tensor
t = data.valid_ds[420][0].data; t.shape
```




    torch.Size([3, 352, 352])



Notice that `t` is a rank 3 tensor, because we are assigning only 1 of the photo from the valid set in `t`, which is just a standard RGB photo of a pug, which is a rank 3 tensor (3 x 352 x 352).

One thing about PyTorch is that it expects to work on mini-batch instead of an individual thing, so in this case, we have to create a mini-batch of size 1, we can do this by indexing `None`,


```python
t[None].shape
```




    torch.Size([1, 3, 352, 352])



Now we are ready to use PyTorch to run **Stride 2 Convolutions**.


```python
# pass in rank 4 tensor of the selected image, and the kernel
edge = F.conv2d(t[None], k)
```


```python
show_image(edge[0], figsize=(5,5));
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_50_0.png" alt="">


We got our pug back, but this output is after a **Stride 2 Convolution**.


```python
learn.model
```




    Sequential(
      (0): Sequential(
        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (6): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (7): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (1): Sequential(
        (0): AdaptiveConcatPool2d(
          (ap): AdaptiveAvgPool2d(output_size=1)
          (mp): AdaptiveMaxPool2d(output_size=1)
        )
        (1): Flatten()
        (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout(p=0.25)
        (4): Linear(in_features=1024, out_features=512, bias=True)
        (5): ReLU(inplace)
        (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): Dropout(p=0.5)
        (8): Linear(in_features=512, out_features=37, bias=True)
        (9): BatchNorm1d(37, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
      )
    )



So if we study the output from `learn.model`, the very top `Conv2d` shows that we are taking `3` channels and output `64` channels, the `kernel size` is `7x7` instead of the common `3x3`,  have not learn why this is the case, but generally, we use a larger kernel for the very first `Conv2d`, and because we are using a larger kernel size, we have to use a larger padding, we generally go for `kernel size/2` padding to make sure we cover all the EWMM.  

`learn.summary()` prints out output shape up to every layer in the neural network, so let's see what's going on.




```python
print(learn.summary())
```

    ======================================================================
    Layer (type)         Output Shape         Param #    Trainable
    ======================================================================
    Conv2d               [64, 176, 176]       9,408      False     
    ______________________________________________________________________
    BatchNorm2d          [64, 176, 176]       128        True      
    ______________________________________________________________________
    ReLU                 [64, 176, 176]       0          False     
    ______________________________________________________________________
    MaxPool2d            [64, 88, 88]         0          False     
    ______________________________________________________________________
    Conv2d               [64, 88, 88]         36,864     False     
    ______________________________________________________________________
    BatchNorm2d          [64, 88, 88]         128        True      
    ______________________________________________________________________
    ReLU                 [64, 88, 88]         0          False     
    ______________________________________________________________________
    Conv2d               [64, 88, 88]         36,864     False     
    ______________________________________________________________________
    BatchNorm2d          [64, 88, 88]         128        True      
    ______________________________________________________________________
    Conv2d               [64, 88, 88]         36,864     False     
    ______________________________________________________________________
    BatchNorm2d          [64, 88, 88]         128        True      
    ______________________________________________________________________
    ReLU                 [64, 88, 88]         0          False     
    ______________________________________________________________________
    Conv2d               [64, 88, 88]         36,864     False     
    ______________________________________________________________________
    BatchNorm2d          [64, 88, 88]         128        True      
    ______________________________________________________________________
    Conv2d               [64, 88, 88]         36,864     False     
    ______________________________________________________________________
    BatchNorm2d          [64, 88, 88]         128        True      
    ______________________________________________________________________
    ReLU                 [64, 88, 88]         0          False     
    ______________________________________________________________________
    Conv2d               [64, 88, 88]         36,864     False     
    ______________________________________________________________________
    BatchNorm2d          [64, 88, 88]         128        True      
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        73,728     False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    ReLU                 [128, 44, 44]        0          False     
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        8,192      False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    ReLU                 [128, 44, 44]        0          False     
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    ReLU                 [128, 44, 44]        0          False     
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    ReLU                 [128, 44, 44]        0          False     
    ______________________________________________________________________
    Conv2d               [128, 44, 44]        147,456    False     
    ______________________________________________________________________
    BatchNorm2d          [128, 44, 44]        256        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        294,912    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    ReLU                 [256, 22, 22]        0          False     
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        32,768     False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    ReLU                 [256, 22, 22]        0          False     
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    ReLU                 [256, 22, 22]        0          False     
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    ReLU                 [256, 22, 22]        0          False     
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    ReLU                 [256, 22, 22]        0          False     
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    ReLU                 [256, 22, 22]        0          False     
    ______________________________________________________________________
    Conv2d               [256, 22, 22]        589,824    False     
    ______________________________________________________________________
    BatchNorm2d          [256, 22, 22]        512        True      
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        1,179,648  False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    ReLU                 [512, 11, 11]        0          False     
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        2,359,296  False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        131,072    False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        2,359,296  False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    ReLU                 [512, 11, 11]        0          False     
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        2,359,296  False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        2,359,296  False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    ReLU                 [512, 11, 11]        0          False     
    ______________________________________________________________________
    Conv2d               [512, 11, 11]        2,359,296  False     
    ______________________________________________________________________
    BatchNorm2d          [512, 11, 11]        1,024      True      
    ______________________________________________________________________
    AdaptiveAvgPool2d    [512, 1, 1]          0          False     
    ______________________________________________________________________
    AdaptiveMaxPool2d    [512, 1, 1]          0          False     
    ______________________________________________________________________
    Flatten              [1024]               0          False     
    ______________________________________________________________________
    BatchNorm1d          [1024]               2,048      True      
    ______________________________________________________________________
    Dropout              [1024]               0          False     
    ______________________________________________________________________
    Linear               [512]                524,800    True      
    ______________________________________________________________________
    ReLU                 [512]                0          False     
    ______________________________________________________________________
    BatchNorm1d          [512]                1,024      True      
    ______________________________________________________________________
    Dropout              [512]                0          False     
    ______________________________________________________________________
    Linear               [37]                 18,981     True      
    ______________________________________________________________________
    BatchNorm1d          [37]                 74         True      
    ______________________________________________________________________

    Total params: 21,831,599
    Total trainable params: 563,951
    Total non-trainable params: 21,267,648



Generally convolutions have a **stride 2** on the first layer, which is why the height and width of the photo is `176 * 176` after the first layer, and the `64` represents the number of activation we have on the output, also known as output channels, this information aligns well with `learn.model` from above.

In additional, we can also see that as we get deeper in the network, the height and width of the channels are halves of the originals while the number of channels doubled up, which is exactly what we talked about just now, until the point where we are at `11 * 11 * 512`, so the next step is that we would take an average across the `11 * 11` of each of the 512 channels, which is this portion of code `(ap): AdaptiveAvgPool2d(output_size=1)` from `learn.model` and we ended up with a single vector of 512 activations, it then goes down to 37 output activations, because we have 37 (`data.c`) breeds in total of cats and dogs.

Visually, it looks something like this...

<img src="https://i.imgur.com/bZDsI81.png" width="800">

As you can see, when we have that vector of average pool from the `11 * 11 * 512` channels,  to get into 37 activations, the network has to do a matrix multiplication of `512 * 37` parameters to 37 output activiations, which will be compared to the actual result to compute loss.

In our case, we know the ground truth is `pug`, that's the photo we selected, that means we want the output activation to have the highest probability on `pug` output activation, and that activation is the result of the matrix multiplication, so if you think about it, that 512 channels, essentially represent the different features that the network use to evaluate whether the photo shows a cat or a dog, what kind of breed it is, by looking at perhaps how long is the whisker, how long pointy are the ears, colour of nose, etc.

## Heatmap

Previous, we were looking at an average pool of the `11 * 11` for 512 channels, and we ended up with a vector of 512 activations.

What if we take the average pool of each of the activation in the `11 * 11` across 512 channels? We would then end up with a `11 * 11` output activation, and each grid point in that `11 * 11` matrix will be the average of how activated was that area of the photo when it was figuring out that this was a `pug`, and that is how we get the heatmap, which outlines what the neural net focus on when it's trying to predict the classes for the picture.


```python
m = learn.model.eval();
```


```python
# convolutions part of the model
m[0]
```




    Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (4): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (5): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )



Since this is a resnet 34 model, `m[0]` shows a printout of the resnet 34, and ended up with 512 activations.

Although we have the image of our pug, we can't straightaway pass that into our model, because it has to be normalized and turned into a mini-batch and put on the GPU.


```python
# create mini-batch with 1 thing in it, normalize it, pass it to GPU
xb,_ = data.one_item(x)
xb_im = Image(data.denorm(xb)[0])
xb = xb.cuda()
```


```python
from fastai.callbacks.hooks import *
```

We want to hook the convolutional part of the model, giving it a name (e.g. `hook_a`), don't worry about `with hook_output(m[0], grad=True) as hook_g:` for now.

Since we are using PyTorch, when we want to calculate something (a forward pass), you can just act as if the model is a function and pass in x mini-batch `preds = m(xb)`, we aren't really concern with the prediction part of the model because we are more interested at the convolutional part of the model now, which is why we are only hooking that part of the model.

<br>

**Friendly reminder about using `hooked_backward`**

When we hook something in PyTorch, everytime we run that model, it's storing those outputs and so we want to remove the hooks when we got what we want, otherwise when we use the model again, it's going to keep hooking more outputs which will be memory intensive.

So we use something called a context manager, which means we use the `hook` as a context manager, and at the end of the `with` block, it will remove the hook.



```python
def hooked_backward(cat=y):
    with hook_output(m[0]) as hook_a:
        with hook_output(m[0], grad=True) as hook_g:
            preds = m(xb)
            preds[0,int(cat)].backward()
    return hook_a,hook_g
```


```python
hook_a,hook_g = hooked_backward()
```

This is where fastai stored these hooks, we call them with `.stored`


```python
acts  = hook_a.stored[0].cpu()
acts.shape
```




    torch.Size([512, 11, 11])



<img src="https://i.imgur.com/bZDsI81.png" width="800">

`hook_a` is essentially the `11 * 11 * 512` channels in the diagram, and if we take the average of each grid across 512 channels, we would end up with a `11 * 11` rank 2 tensor, as shown below.


```python
avg_acts = acts.mean(0)
avg_acts.shape
```




    torch.Size([11, 11])



After that, we can define the heatmap function and plot the heatmap of the image.


```python
def show_heatmap(hm):
    _,ax = plt.subplots()
    xb_im.show(ax)
    ax.imshow(hm, alpha=0.6, extent=(0,352,352,0),
              interpolation='bilinear', cmap='magma');
```

`extent=(0, 352, 352, 0)` - expands the image from 11 by 11 to 352 by 352.

`interpolation = 'bilinear'` - ensures that the image isn't blocky.

`cmap = 'magma'` -  use magma colour map.


```python
show_heatmap(avg_acts)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/pets-cnn/output_73_0.png" alt="">


Now we know exactly what the neural net look at when predicting this particular image, it's almost as if it's seen by a human, absolutely astounding! we will most probably build CNN again in the future blogpost since it's so much fun, but for the next blogpost, we will explore text & image generative models, which we generate new data, it's one of the area that deep learning has developed the most in 2018, so it would be super exciting to learn that!

That is all for me for this blogpost, thank you for reading my blogpost, shoutout to [fast.ai](https://www.fast.ai/) for their resources, ciao!
