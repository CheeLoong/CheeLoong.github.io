---
title: "Bear Image Classifier with resnet34"
date: 2019-03-14
permalink: /bears/
tags: [fastai, deep learning, resnet34, bears, image web scrape]
excerpt: "Building Bear Classifier using fastai resnet34"
mathjax: "true"
published: false
---


# Bear Classifier with resnet34

In this blogpost, we will try to create an image dataset through Google Images, do some data cleaning, and then use resnet34 to predict if the given image is a black bear, grizzly bear, or a teddy bear.

Why bear? well cuz everybody loves bear, ha. The idea really is to learn how we can utilize Google Image to create image data for our model to learn. Loosely speaking, if you can build a bear classifier, you can build any classifier!

Let's get started!



# Colab Cloud Server VM setup & FastAI Configurations

First we need to use GPU for deep learning applications, so instead of buying, we can rent it from cloud servers. There are many other server options, but basically I chose Colab because issa **FREE**.

To learn how to set up a Colab Server which supports fastai library and its applications, [click here](https://course.fast.ai/start_colab.html).

NB: This is a free service that may not always be available, and requires extra steps to ensure your work is saved. Be sure to read the docs on the Colab web-site to ensure you understand the limitations of the system.


```python
# Permit collaboratory instance to read/write to Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
base_dir = root_dir + 'fastai-v3/'
```

    Mounted at /content/gdrive


We import all the necessary packages. We are going to work with the [fastai V1 library](http://www.fast.ai/2018/10/02/fastai-ai/) which sits on top of [Pytorch 1.0](https://hackernoon.com/pytorch-1-0-468332ba5163). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.


```python
from fastai.vision import *
from fastai.metrics import error_rate
```


```python
# this line creates data & models folder and functionalities integration (e.g. untar_data, model.save)  
  !curl -s https://course.fast.ai/setup/colab | bash
```

    Updating fastai...
    Done.


Every notebook starts with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook.


```python
%reload_ext autoreload
%autoreload 2
%matplotlib inline
```

## Get & Download a list of URLs

### Search and scroll

Go to [Google Images](http://images.google.com) and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.

Scroll down until you've seen all the images you want to download, or until you see a button that says 'Show more results'. All the images you scrolled past are now available to download. To get more, click on the button, and continue scrolling. The maximum number of images Google Images shows is 700.

It is a good idea to put things you want to exclude into the search query, for instance if you are searching for the Eurasian wolf, "canis lupus lupus", it might be a good idea to exclude other variants:

    "canis lupus lupus" -dog -arctos -familiaris -baileyi -occidentalis

You can also limit your results to show only photos by clicking on Tools and selecting Photos from the Type dropdown.

### Download into file

Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.

Press <kbd>Ctrl</kbd><kbd>Shift</kbd><kbd>J</kbd> in Windows/Linux and <kbd>Cmd</kbd><kbd>Opt</kbd><kbd>J</kbd> in Mac, and a small window the javascript 'Console' will appear. That is where you will paste the JavaScript commands.

You will need to get the urls of each of the images. You can do this by running the following commands:

```javascript
urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);
window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\n')));
```

In this particular blogpost, we have 3 different categories of images; black, teddies, & grizzly, so be sure to download each of them with the JavaScript commands. We should have 3 files:
  - url_black.txt
  - url_teddies.txt
  - url_grizzly.txt

### Create directory, upload url.txt into your server and download the images

To put these into steps:
1. Create relevant directory (e.g. `fastai-v3/data/bears/black`)
2. Upload the 3 url.txt files to `path` (i.e. `fastai-v3/data/bears`)
3. Use fastai `download_images` to download your images from their respective urls.



```python
# define path
path = Path(base_dir + 'data/bears')
```


```python
# create 'fastai-v3/data/bears/black' folder
folder = 'black'
file = 'url_black.txt'

dest = path/folder
dest.mkdir(parents=True, exist_ok=True)

# drag and drop the urls.txt to Google Drive 'path'

# download images from the urls.txt
download_images(path/file, dest, max_pics=200)
```



<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_1_0.png" alt="">





```python
# create 'fastai-v3/data/bears/teddies' folder
folder = 'teddies'
file = 'url_teddies.txt'

dest = path/folder
dest.mkdir(parents=True, exist_ok=True)

# drag and drop the urls.txt to Google Drive 'path'

# download images from the urls.txt
download_images(path/file, dest, max_pics=200)
```



<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_2_0.png" alt="">





```python
# create 'fastai-v3/data/bears/grizzly' folder
folder = 'grizzly'
file = 'url_grizzly.txt'

dest = path/folder
dest.mkdir(parents=True, exist_ok=True)

# drag and drop the urls.txt to Google Drive 'path'

# download images from the urls.txt
download_images(path/file, dest, max_pics=200)
```



<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_3_0.png" alt="">




To remove any images that can't be opened:


```python
classes = ['teddies','grizzly','black']

for c in classes:
    print(c)
    verify_images(path/c, delete=True, max_size=500)
```

<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_4_0.png" alt="">


## View data

Now when we are creating `ImageDataBunch`, we can specify that our training set is in the current folder by including the args `train = "."` and we can also specify to set aside valid set which will be 20% of our training set by including the args `valid_pct = 0.2`.


```python
np.random.seed(42) # to ensure we use the same train and valid set everytime we run the code
data = ImageDataBunch.from_folder(path, train=".", valid_pct=0.2,
        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)
```


```python
# If you already cleaned your data, run this cell instead of the one before
# np.random.seed(42)
# data = ImageDataBunch.from_csv(".", folder=".", valid_pct=0.2, csv_labels='cleaned.csv',
#         ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)
```

Good! Let's take a look at some of our pictures then.


```python
# tells us the target labels of our data
data.classes
```




    ['black', 'grizzly', 'teddies']




```python
data.show_batch(rows=3, figsize=(7,8))
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_30_0.png" alt="">


`data.c`: tells us the number of possible labels, there's more to it, but we will explore it in the future.

`data.train_ds`: training size

`data.valid_ds`: test size


```python
data.classes, data.c, len(data.train_ds), len(data.valid_ds)
```




    (['black', 'grizzly', 'teddies'], 3, 460, 115)



## Train model


```python
learn = create_cnn(data, models.resnet34, metrics=error_rate)
```

    Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /root/.torch/models/resnet34-333f7ec4.pth
    87306240it [00:00, 96190082.73it/s]



```python
learn.fit_one_cycle(4)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_5_0.png" alt="">




```python
# save the tuned weights
learn.save('stage-1')
```

6.96% validation error rate with resnet34, looking good, lets unfreeze the model and tune the learning parameter!


```python
# unfreeze the model
learn.unfreeze()
```


```python
# learning rate finder
learn.lr_find()
```





    LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.



```python
learn.recorder.plot()
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_40_0.png" alt="">


The idea is to choose the learner rate range that exhibit the greatest descent, in my plot, I picked, 2e-5 to 1e-3.


```python
learn.fit_one_cycle(2, max_lr=slice(2e-5,1e-3))
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_6_0.png" alt="">



Since unfreezing the learner does not help improving the model, we will revert back to our previous learner.


```python
# load our previously saved parameters/weights
learn.load('stage-1');
```

## Interpretation


```python
interp = ClassificationInterpretation.from_learner(learn)
```


```python
interp.plot_confusion_matrix()
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_47_0.png" alt="">



```python
# plotting the top losses in the valid set
interp.plot_top_losses(9, figsize=(15,11), heatmap = False)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_48_0.png" alt="">


I guess we can kind of tell why our algorithm is having a hard time classifying these images with top losses. These images usually come with random noise that's very hard to pinpoint.

Now, don't get me wrong, this is a very decent model with only 8 misclassifications out of 115 predictions, but there's always room for improvement right?

## Cleaning Up

Some of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be.

Using the `ImageCleaner` widget from `fastai.widgets` we can prune our top losses, removing photos that don't belong.

If you are using Colab like I do, we won't be able to use `ImageCleaner` since its a widget not supported by Colab. Read more [here](https://forums.fast.ai/t/imagecleaner-hanging-in-colab/39579).

There's a workaround for this, which is to use `ImageCleaner` on our local machine, and then upload the `cleaned.csv` to the google drive.

To learn how to use `ImageCleaner` on local machine, click [here](https://forums.fast.ai/t/imagecleaner-missing-argument-in-lesson-2-download-notebook/36537/23).

Proceed after you have cleanse your data.

### View Data

Make sure you upload `cleaned.csv` to `path`, then recreate your ImageDataBunch from your `cleaned.csv` to include the changes you made in your data!


```python
# recreate ImageDataBunch
np.random.seed(42)
data = ImageDataBunch.from_csv(path, folder=".", valid_pct=0.2, csv_labels='cleaned.csv',
        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)
```

Let's check the cleaned data, seems like we now have  451 images, with 361 in the train set and 90 in the valid set.


```python
# Let's check the cleaned data
data
```




    ImageDataBunch;

    Train: LabelList (361 items)
    x: ImageList
    Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
    y: CategoryList
    black,grizzly,grizzly,grizzly,grizzly
    Path: /content/gdrive/My Drive/fastai-v3/data/bears;

    Valid: LabelList (90 items)
    x: ImageList
    Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
    y: CategoryList
    teddies,grizzly,teddies,teddies,black
    Path: /content/gdrive/My Drive/fastai-v3/data/bears;

    Test: None



### Retrain the model


```python
learn = create_cnn(data, models.resnet34, metrics=error_rate)
```


```python
learn.fit_one_cycle(4)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_7_0.png" alt="">




```python
learn.save('stage-1-cleaned')
```

4.44% valid error rate, that's better than before.

### Interpretation


```python
interp = ClassificationInterpretation.from_learner(learn)
```


```python
interp.plot_confusion_matrix()
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_64_0.png" alt="">



```python
# plotting the top losses in the valid set
interp.plot_top_losses(9, figsize=(15,11), heatmap = False)
```


<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_65_0.png" alt="">



To be honest, I think there's room for improvement still.

But I am lazy, so lets say at this point, we are ready to put our model in production. How do we go about to do that?

## Putting model in production

First thing first, let's export the content of our `Learner` object for production:


```python
learn.export()
```

This will create a file named 'export.pkl' in the directory where we were working that contains everything we need to deploy our model (the model, the weights but also some metadata like the classes or the transforms/normalization used).

You probably want to use CPU for inference, except at massive scale (and you almost certainly don't need to train in real-time). If you don't have a GPU that happens automatically. You can test your model on CPU like so:


```python
# comment the following if you are using cpu
defaults.device = torch.device('cpu')
```


```python
img = open_image(path/'black'/'00000120.jpg')
img
```




<img src="{{ site.url }}{{ site.baseurl }}/assets/images/bears/output_73_0.png" alt="">



We create our `Learner` in production enviromnent like this, just make sure that `path` contains the file 'export.pkl' from before.


```python
learn = load_learner(path)
```


```python
pred_class,pred_idx,outputs = learn.predict(img)
print(pred_class)
```

    black


In this blogpost, we have managed to:
- Scrap google images using Javascript commands on Javascript console
- Built a resnet34 bear image classifier
- Image data cleaning using `ImageCleaner`
- Putting model in production (running on CPU)

If you want to learn more about deep learning topic, make sure you visit [fast.ai](https://www.fast.ai/).

Coming up next, we will build web application for our classification algorithms, or maybe I will build another classifier before we move to building web application, a bear classifier isn't really helpful ya know.

Thank you for reading, I will see you soon!
